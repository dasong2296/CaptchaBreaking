{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f273376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ 192 64 4 37\n",
      "79AY tensor([12]) tensor([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 3.9386 Acc: 0.0000 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  7.07it/s]\n",
      "Test : 1 Loss: 3.9375 Acc: 0.0000 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.96it/s]\n",
      "Epoch: 2 Loss: 3.7136 Acc: 0.0000 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  7.01it/s]\n",
      "Test : 2 Loss: 3.7128 Acc: 0.0000 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  6.01it/s]\n",
      "Epoch: 3 Loss: 3.6909 Acc: 0.0000 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.97it/s]\n",
      "Test : 3 Loss: 3.6858 Acc: 0.0000 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  6.08it/s]\n",
      "Epoch: 4 Loss: 3.6776 Acc: 0.0000 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 4 Loss: 3.6875 Acc: 0.0000 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.91it/s]\n",
      "Epoch: 5 Loss: 3.1963 Acc: 0.0000 : 100%|████████████████████████████████████| 100/100 [00:15<00:00,  6.64it/s]\n",
      "Test : 5 Loss: 3.1855 Acc: 0.0000 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.84it/s]\n",
      "Epoch: 6 Loss: 2.1198 Acc: 0.0137 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.75it/s]\n",
      "Test : 6 Loss: 2.0304 Acc: 0.0094 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.87it/s]\n",
      "Epoch: 7 Loss: 1.0343 Acc: 0.1941 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.77it/s]\n",
      "Test : 7 Loss: 1.3652 Acc: 0.0656 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.98it/s]\n",
      "Epoch: 8 Loss: 0.6052 Acc: 0.4769 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.75it/s]\n",
      "Test : 8 Loss: 0.6717 Acc: 0.4016 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.88it/s]\n",
      "Epoch: 9 Loss: 0.4151 Acc: 0.6247 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 9 Loss: 0.4917 Acc: 0.5711 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  6.04it/s]\n",
      "Epoch: 10 Loss: 0.2953 Acc: 0.7015 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.84it/s]\n",
      "Test : 10 Loss: 1.1938 Acc: 0.4367 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.90it/s]\n",
      "Epoch: 11 Loss: 0.2394 Acc: 0.7442 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.68it/s]\n",
      "Test : 11 Loss: 0.3567 Acc: 0.6438 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.98it/s]\n",
      "Epoch: 12 Loss: 0.2061 Acc: 0.7683 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.72it/s]\n",
      "Test : 12 Loss: 0.2055 Acc: 0.7828 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.00it/s]\n",
      "Epoch: 13 Loss: 0.1693 Acc: 0.8038 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.81it/s]\n",
      "Test : 13 Loss: 0.9140 Acc: 0.3680 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.52it/s]\n",
      "Epoch: 14 Loss: 0.1442 Acc: 0.8181 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 14 Loss: 0.2352 Acc: 0.7336 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.90it/s]\n",
      "Epoch: 15 Loss: 0.1345 Acc: 0.8331 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.75it/s]\n",
      "Test : 15 Loss: 0.1265 Acc: 0.8305 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.01it/s]\n",
      "Epoch: 16 Loss: 0.1276 Acc: 0.8351 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 16 Loss: 0.1099 Acc: 0.8469 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.88it/s]\n",
      "Epoch: 17 Loss: 0.0930 Acc: 0.8759 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 17 Loss: 0.0936 Acc: 0.8617 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n",
      "Epoch: 18 Loss: 0.0872 Acc: 0.8687 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.76it/s]\n",
      "Test : 18 Loss: 0.0904 Acc: 0.8758 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.48it/s]\n",
      "Epoch: 19 Loss: 0.0754 Acc: 0.8927 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.74it/s]\n",
      "Test : 19 Loss: 0.0933 Acc: 0.8750 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.89it/s]\n",
      "Epoch: 20 Loss: 0.0822 Acc: 0.8901 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 20 Loss: 0.0866 Acc: 0.8664 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.94it/s]\n",
      "Epoch: 21 Loss: 0.0794 Acc: 0.8788 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.70it/s]\n",
      "Test : 21 Loss: 0.1199 Acc: 0.8297 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "Epoch: 22 Loss: 0.0707 Acc: 0.8876 : 100%|███████████████████████████████████| 100/100 [00:15<00:00,  6.52it/s]\n",
      "Test : 22 Loss: 0.0726 Acc: 0.8898 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.79it/s]\n",
      "Epoch: 23 Loss: 0.0624 Acc: 0.9087 : 100%|███████████████████████████████████| 100/100 [00:15<00:00,  6.58it/s]\n",
      "Test : 23 Loss: 0.0509 Acc: 0.9148 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "Epoch: 24 Loss: 0.0613 Acc: 0.9072 : 100%|███████████████████████████████████| 100/100 [00:15<00:00,  6.63it/s]\n",
      "Test : 24 Loss: 0.0631 Acc: 0.9094 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.00it/s]\n",
      "Epoch: 25 Loss: 0.0569 Acc: 0.9054 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 25 Loss: 0.1226 Acc: 0.8430 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.97it/s]\n",
      "Epoch: 26 Loss: 0.0579 Acc: 0.9091 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 26 Loss: 0.0606 Acc: 0.8961 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.90it/s]\n",
      "Epoch: 27 Loss: 0.0539 Acc: 0.9097 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.71it/s]\n",
      "Test : 27 Loss: 0.1329 Acc: 0.8266 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.85it/s]\n",
      "Epoch: 28 Loss: 0.0566 Acc: 0.9136 : 100%|███████████████████████████████████| 100/100 [00:15<00:00,  6.64it/s]\n",
      "Test : 28 Loss: 0.0505 Acc: 0.9117 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "Epoch: 29 Loss: 0.0573 Acc: 0.9079 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.67it/s]\n",
      "Test : 29 Loss: 0.1506 Acc: 0.8000 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n",
      "Epoch: 30 Loss: 0.0547 Acc: 0.9092 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.82it/s]\n",
      "Test : 30 Loss: 0.0436 Acc: 0.9078 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "\n",
    "from captcha.image import ImageCaptcha\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import string\n",
    "characters = '-' + string.digits + string.ascii_uppercase\n",
    "width, height, n_len, n_classes = 192, 64, 4, len(characters)\n",
    "n_input_length = 12\n",
    "print(characters, width, height, n_len, n_classes)\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, characters, length, width, height, input_length, label_length):\n",
    "        super(CaptchaDataset, self).__init__()\n",
    "        self.characters = characters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.input_length = input_length\n",
    "        self.label_length = label_length\n",
    "        self.n_class = len(characters)\n",
    "        self.generator = ImageCaptcha(width=width, height=height)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        random_str = ''.join([random.choice(self.characters[1:]) for j in range(self.label_length)])\n",
    "        image = to_tensor(self.generator.generate_image(random_str))\n",
    "        target = torch.tensor([self.characters.find(x) for x in random_str], dtype=torch.long)\n",
    "        input_length = torch.full(size=(1, ), fill_value=self.input_length, dtype=torch.long)\n",
    "        target_length = torch.full(size=(1, ), fill_value=self.label_length, dtype=torch.long)\n",
    "        return image, target, input_length, target_length\n",
    "\n",
    "dataset = CaptchaDataset(characters, 1, width, height, n_input_length, n_len)\n",
    "image, target, input_length, label_length = dataset[0]\n",
    "print(''.join([characters[x] for x in target]), input_length, label_length)\n",
    "to_pil_image(image)\n",
    "\n",
    "batch_size = 128\n",
    "train_set = CaptchaDataset(characters, 100 * batch_size, width, height, n_input_length, n_len)\n",
    "valid_set = CaptchaDataset(characters, 10 * batch_size, width, height, n_input_length, n_len)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=8)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=8)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_classes, input_shape=(3, 64, 128)):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        channels = [32, 64, 128, 256, 256]\n",
    "        layers = [2, 2, 2, 2, 2]\n",
    "        kernels = [3, 3, 3, 3, 3]\n",
    "        pools = [2, 2, 2, 2, (2, 1)]\n",
    "        modules = OrderedDict()\n",
    "\n",
    "        def cba(name, in_channels, out_channels, kernel_size):\n",
    "            modules[f'conv{name}'] = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                                               padding=(1, 1) if kernel_size == 3 else 0)\n",
    "            modules[f'bn{name}'] = nn.BatchNorm2d(out_channels)\n",
    "            modules[f'relu{name}'] = nn.ReLU(inplace=True)\n",
    "        \n",
    "        last_channel = 3\n",
    "        for block, (n_channel, n_layer, n_kernel, k_pool) in enumerate(zip(channels, layers, kernels, pools)):\n",
    "            for layer in range(1, n_layer + 1):\n",
    "                cba(f'{block + 1}{layer}', last_channel, n_channel, n_kernel)\n",
    "                last_channel = n_channel\n",
    "            modules[f'pool{block + 1}'] = nn.MaxPool2d(k_pool)\n",
    "        modules[f'dropout'] = nn.Dropout(0.25, inplace=True)\n",
    "\n",
    "        self.cnn = nn.Sequential(modules)\n",
    "        self.lstm = nn.LSTM(input_size=self.infer_features(), hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=256, out_features=n_classes)\n",
    "\n",
    "    def infer_features(self):\n",
    "        x = torch.zeros((1,) + self.input_shape)\n",
    "        x = self.cnn(x)\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[-1])\n",
    "        return x.shape[1]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[-1])\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Model(n_classes, input_shape=(3, height, width))\n",
    "inputs = torch.zeros((32, 3, height, width))\n",
    "outputs = model(inputs)\n",
    "outputs.shape\n",
    "model = Model(n_classes, input_shape=(3, height, width))\n",
    "model = model.cuda()\n",
    "model\n",
    "\n",
    "def decode(sequence):\n",
    "    a = ''.join([characters[x] for x in sequence])\n",
    "    s = ''.join([x for j, x in enumerate(a[:-1]) if x != characters[0] and x != a[j+1]])\n",
    "    if len(s) == 0:\n",
    "        return ''\n",
    "    if a[-1] != characters[0] and s[-1] != a[-1]:\n",
    "        s += a[-1]\n",
    "    return s\n",
    "\n",
    "def decode_target(sequence):\n",
    "    return ''.join([characters[x] for x in sequence]).replace(' ', '')\n",
    "\n",
    "def calc_acc(target, output):\n",
    "    output_argmax = output.detach().permute(1, 0, 2).argmax(dim=-1)\n",
    "    target = target.cpu().numpy()\n",
    "    output_argmax = output_argmax.cpu().numpy()\n",
    "    a = np.array([decode_target(true) == decode(pred) for true, pred in zip(target, output_argmax)])\n",
    "    return a.mean()\n",
    "\n",
    "def train(model, optimizer, epoch, dataloader):\n",
    "    model.train()\n",
    "    loss_mean = 0\n",
    "    acc_mean = 0\n",
    "    with tqdm(dataloader) as pbar:\n",
    "        for batch_index, (data, target, input_lengths, target_lengths) in enumerate(pbar):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            output_log_softmax = F.log_softmax(output, dim=-1)\n",
    "            loss = F.ctc_loss(output_log_softmax, target, input_lengths, target_lengths)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "            acc = calc_acc(target, output)\n",
    "            \n",
    "            if batch_index == 0:\n",
    "                loss_mean = loss\n",
    "                acc_mean = acc\n",
    "            \n",
    "            loss_mean = 0.1 * loss + 0.9 * loss_mean\n",
    "            acc_mean = 0.1 * acc + 0.9 * acc_mean\n",
    "            \n",
    "            pbar.set_description(f'Epoch: {epoch} Loss: {loss_mean:.4f} Acc: {acc_mean:.4f} ')\n",
    "\n",
    "def valid(model, optimizer, epoch, dataloader):\n",
    "    model.eval()\n",
    "    with tqdm(dataloader) as pbar, torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        acc_sum = 0\n",
    "        for batch_index, (data, target, input_lengths, target_lengths) in enumerate(pbar):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            output_log_softmax = F.log_softmax(output, dim=-1)\n",
    "            loss = F.ctc_loss(output_log_softmax, target, input_lengths, target_lengths)\n",
    "            \n",
    "            loss = loss.item()\n",
    "            acc = calc_acc(target, output)\n",
    "            \n",
    "            loss_sum += loss\n",
    "            acc_sum += acc\n",
    "            \n",
    "            loss_mean = loss_sum / (batch_index + 1)\n",
    "            acc_mean = acc_sum / (batch_index + 1)\n",
    "            \n",
    "            pbar.set_description(f'Test : {epoch} Loss: {loss_mean:.4f} Acc: {acc_mean:.4f} ')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3, amsgrad=True)\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, optimizer, epoch, train_loader)\n",
    "    valid(model, optimizer, epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeec7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.0340 Acc: 0.9315 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  7.04it/s]\n",
      "Test : 1 Loss: 0.0285 Acc: 0.9367 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.67it/s]\n",
      "Epoch: 2 Loss: 0.0281 Acc: 0.9360 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  7.00it/s]\n",
      "Test : 2 Loss: 0.0229 Acc: 0.9461 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.94it/s]\n",
      "Epoch: 3 Loss: 0.0326 Acc: 0.9403 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.82it/s]\n",
      "Test : 3 Loss: 0.0182 Acc: 0.9508 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.89it/s]\n",
      "Epoch: 4 Loss: 0.0283 Acc: 0.9415 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "Test : 4 Loss: 0.0269 Acc: 0.9477 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.80it/s]\n",
      "Epoch: 5 Loss: 0.0244 Acc: 0.9451 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 5 Loss: 0.0213 Acc: 0.9516 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.90it/s]\n",
      "Epoch: 6 Loss: 0.0218 Acc: 0.9476 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.76it/s]\n",
      "Test : 6 Loss: 0.0189 Acc: 0.9500 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.64it/s]\n",
      "Epoch: 7 Loss: 0.0305 Acc: 0.9408 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.77it/s]\n",
      "Test : 7 Loss: 0.0162 Acc: 0.9570 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  6.00it/s]\n",
      "Epoch: 8 Loss: 0.0280 Acc: 0.9345 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 8 Loss: 0.0168 Acc: 0.9570 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  5.77it/s]\n",
      "Epoch: 9 Loss: 0.0246 Acc: 0.9383 : 100%|████████████████████████████████████| 100/100 [00:14<00:00,  6.82it/s]\n",
      "Test : 9 Loss: 0.0173 Acc: 0.9437 : 100%|██████████████████████████████████████| 10/10 [00:01<00:00,  6.05it/s]\n",
      "Epoch: 10 Loss: 0.0234 Acc: 0.9431 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.83it/s]\n",
      "Test : 10 Loss: 0.0209 Acc: 0.9508 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.02it/s]\n",
      "Epoch: 11 Loss: 0.0251 Acc: 0.9417 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.82it/s]\n",
      "Test : 11 Loss: 0.0246 Acc: 0.9406 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.07it/s]\n",
      "Epoch: 12 Loss: 0.0199 Acc: 0.9445 : 100%|███████████████████████████████████| 100/100 [00:16<00:00,  6.20it/s]\n",
      "Test : 12 Loss: 0.0212 Acc: 0.9453 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.04it/s]\n",
      "Epoch: 13 Loss: 0.0230 Acc: 0.9433 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.79it/s]\n",
      "Test : 13 Loss: 0.0172 Acc: 0.9516 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  5.95it/s]\n",
      "Epoch: 14 Loss: 0.0241 Acc: 0.9432 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.75it/s]\n",
      "Test : 14 Loss: 0.0176 Acc: 0.9523 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.03it/s]\n",
      "Epoch: 15 Loss: 0.0244 Acc: 0.9404 : 100%|███████████████████████████████████| 100/100 [00:14<00:00,  6.85it/s]\n",
      "Test : 15 Loss: 0.0240 Acc: 0.9406 : 100%|█████████████████████████████████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, amsgrad=True)\n",
    "epochs = 15\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, optimizer, epoch, train_loader)\n",
    "    valid(model, optimizer, epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5bc9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: KK43\n",
      "pred: KK43\n",
      "true: EAJD\n",
      "pred: EAJD\n",
      "true: HA83\n",
      "pred: HA83\n",
      "true: OP47\n",
      "pred: OP47\n",
      "true: HVF4\n",
      "pred: HVF4\n",
      "true: 4BW5\n",
      "pred: 4BW5\n",
      "true: UQFZ\n",
      "pred: UQFZ\n",
      "true: U2UY\n",
      "pred: U2UY\n",
      "true: NM9C\n",
      "pred: NM9C\n",
      "true: 3DZX\n",
      "pred: 3DZX\n",
      "true: 8SP2\n",
      "pred: 8SP2\n",
      "true: 0TUL\n",
      "pred: OTUL\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAABACAIAAADDDu+IAAAdN0lEQVR4nO196XIcx7XmOVlLZlX1gp0guIG7SEqmSXqV7Ts/bjg8M08wEY6YB/Az+KefwW/gN5gfvhGeO+O519osUYtFgou4byCx9FqVS1XmmR/V3QSJBgigmyKlez+RCjRRXZWVeeqs38nCRqHhP/Gf2Cv8Nz2A7wMyrcofYi728N3VdvOzW0uXjp+ZqU3s4QxvFuxND+A7j1IC/uXzD1fbzYEk7eq7f/78g5V247NbS69phK8VOxIgBCisbWXd1U6rJVPr3Ose1ncFo0vA4FuXjp8Z69BejUyr8s8oJ9mhBkJydHf58Z+//OiruzfXGutZlhHRKBf+3mBECbh0/MxsbfK/Xnj/W7ZfoyjOjcDtnWgiSrWUWrfS7tWHt68+vMsA9nvJz35waf/8fBJFuOcrfy8wugcziv+0ZwwUJwDM1iZ/c+Hne776K5xoAmh02x9e/2ql1Uy1kloXxphAF9ev/LpaSYQA/A8tQjEXM7WJ31z4OexGAjYKzZvymsdlOrcUoNTkmVFdmT1aXb777Ekz7QAgAICHmc1XZePB6jIP/EoUReE4p+CNPJGjYLfjfEvCrkvHz4xlDFuasLW0+39uXFtbfZjKbqqUNAoQAQgAgCAKRSLE8X0HfnX24lS1vufLv4S3ZHJfH8ZoO0YfSfnDiAMYroEQQBrdbj57sPqUbEFI0BceQABEmSuV68Dz7q8+AaBYRFHAR3SqN07uZ7eWSrvw/cMbDLs2YlyCu6UJQ3JIFp1zzwUHELCnggABoC2z/3fl8umDR94/9cMoEH0R2zvKyUXAi8fe6aqsqzKpNbzgZQ0+EPOIMUJGAGCJhZ6IgrgScjYmtwwBTF5kSqZa5s4CQhyKRIiYR6Oc9tLxMx/f+Pr0wiIAKwrnAucx9t0NaIcIEALIXEstMy0ducE/lv4yAyIAAiKArspMnje7qc4NIowe1w8M83S13kg7f7v6ZSNtI0MEBCSiFy7hh1bEOSIAkCVkbN9Pj7ybzMwi4vYDKUPLTCtpdPmZB2EiooRHjG3Ma6Bz7ub9e1ce35YuZ4Cz1fovz10cRYBEyEUQXjz2zrWHD/5+4+aFxWOnDxyM4pix72osMlQDocnzr+5fb8suIQAAAfqen4i4KmIi05EyVdI6QkBH1FXZ09YaMoxCkXCxZynaGNGIIHy49myl03i8voKI6CERkLUE0BdmYoyYR8gAgKxjsUiPTk7PVkU9qiFstx4EtNZpfXT9q2baRURHrsLDn546f2z+EAJSX48iQm6LhkkfNVc7OmOACJBqOQOTe1ttBCCirpZ/u/bl48aqLdwnN9Ik4ifjwwiMRtbfbwQvCxACqNystdurrU6qJBABIgE5Rofm5n60eCr0wk/u/OPO48cdJZ0jAnraWv/LlQ9nkun/cvZHMJpxHXzX9ZPdvWl1ZdoScTDLhM4huefrbch+ef+zhfpkTVRxayvWW0Upl5vry801hmidm67Wuipz5AC9l9aRPCAG5TyUDuCe7w4QiVwnS1c7zWbaRgCP3FqrsX9iqlrdbsxvA7ZyujdnojE3xVd37q61O44AABiyapzMzVYP7ascnpk/MD33z+/8eHHf/oRHCOjIdVX2bL292m5++s3V7R/9XYKolB8ioud6AZCgdOqBCPoeGoHKddEWUpntU+QEgMgiLqJQiCAkIgLwkW05ckvkystBlitltDIj8hf6UoiAHjx6cF9r9fZLz1Zp65cFCBFUbpSSmVLkHAAgwL7q5K9P/+y9hXPMY9wPq0n1n85c2jcxHXMBgAhIBDq3JxcO57YY10wQkCsFp5xtJATYsMx9b77njxE6hh5j5L9SSSDAVKV29tBR3/MJwHME1jFHm12nQfhQynKm5JX7t6QelQAzGF+m1eT8rGPPNe5biO3rfcNqYUjMB2QACATEEGs8mU2mp+LJ0OMOKAzCelJ7//T5ioixryUAcS3tRAEfScmX1wcgdJJnKe8WohA8CYVgXuDIEtnBMQgIgDS4PBIwC2xHK/GCLBJx6bz8BScEAbTN23nazFPpckREAKlVp9tRZqTqY+n19x4K3/+mcb9luzmaUc75urFN6mGYE41Y+A48AtdzoTcj5mK6Wp+uTnRUlmlJRJlKO2m7mXWmq/UXY5ldgwAQmKj4xZn2gevHTsZzLImuPbolW6vKFJYAEJCxSpgknAs/yGyRqqzhVrRYV6JL6BC8bXxSAljvtq8+uF0UBSAwAEbE3AvHI2CO+nK2dDm9Rlh44EPpCI0j5MaeBQOT541252bn5lStGgo+VgdgnNgmbT00CiOGWN6mA6d4qnnXBBJocuNBMY/OHz35tLWWagmIjtydpw8OTM9OJjWP4agxBcIsn/mf0//D/shVqY7oTkzPfPj1l7dXHliyQICA0xMTPz/xbuB5uS0+v73EOlnr4NMgZgy3i2gQgMhlWmVGq9wg6y/m5iMJTNzQldXwWe/GEQFHWWQihizmPAo5D0JT5AAoc7Nyfy2dzKY4vZ2e0Pb1vqF5IGSuZ9uQUAfm0b47jF7OC8dCTFcnpir1VEmV69wWjTRda7fasjtZqY04FwzYDE7PCAABAMAQA2T1iRpr+qRtmRdKQlGJYp+xv1378szC0doqHUl+MSfmd3qNXjYUHIJjULwYfhGQ53mXwgtZgF97dymnLQVtxyAARJypTrxz8Ohqu6mLHBGsoUwxo97qGH6byHoLDdT3TAkpyKP5pyfd7MsHIUA1is8vnlxpratcA2Dh7PXH9xem5upJ1d+gBsZSdiEAcET9qAuIUpmtNBtf3r1OALeWH/76/K9iLkLgbKckp3KAxIPQTYmgGnmMPc8SAAiIpmh6gs0IfKZJAmLEeRRyMcJdMGTVKJmpTkxWarooclsAwTqxdcBJgOnR/cfdY8TVGT7X5Hq+MQLjKuKKB0ZsvrmKiKZr9alqnQchAug8l1pJo5yzg4PHRVwiR4VxzhIMZpng799cAQAC+vnZH4ooElH0SveLADKtpFbK6NKdTYNs/sCUPwEFK146GAF9hx717FbMo3cXT0VBuPe7AELG5idmTswf8j0GQICgtfxfxrRHYwbuDaOvzrDpJgDsuYoMMeZh5HsiDIekVxAnk+q5w8dDPyAgRFC5LlmSZVw6Vs4vERKgw35yERB+fOLszC7pfETUztJ/3PtG5zkhAhD3g8vhh41wxdskfAjACJF6kYQIecRH0kAA4DNW0oBCPyACBJCFmbzztZLp6MXEXWEsqzM8CsPe/4CIRBiePHjYgc20KpdusFRSK8ZYHPLJpKZzowuTO7v08PbC1Gw1TsrHdlzFZ2KW+QZYQY4AkIASwWfrk+8uniCinatfAiqrYCo3pS+V2Wy+mLY5ywPrQzA4snBOFrkqCuscloeOcgMvD6MPxFArbDSg1VSiEkUjVWp3i9FXZ4gGQgBivdo7Ihqb3157qPN8td3YqOv62u8jAjg8u8/3PADQucm0zoxyrvQ6x8f5RcqDrmP5xlxizEWyR1JfX6sghFbI1RjTyCNvwySgdfSg1X7QalkiBAACabTUWo7D1pQnhL4jJk1x7erSWM68K4y+OkMTidAvUgIRdZR8ut68++zJv3z+4UDXDbTfeqd19cHtOBTcD8oagsx1KUO0IQIcnR1GAI4ih/0ED8JIOoGgxyoA8EBU8jh28UbvGxFsUbS6nXa3a4uiZEFlWn1156YyIyX9iCDwvCgUMReB75c1PmlME7UcLUW5W4xldYa6nATYf0IRwNFqs/XXry+rIocNum6g/X526t2Yi4RHoR8AgCnyv3/z9XJjLdUS+rTf0elLCB5YH/uVCkSwe2+KJNcjhiARCfQuzJ04kExvLMUTgYds0tGEc75XRqWUaa1yNfIyE2Ps8PS+I7MLDFkvvmTQda5bGDlqoW13GGV1SkP0sgARAQ/CALkIRMnMss5lRtbipBbFG3Vdqf1+c+Hnc/Xp4/OHju8/5DMfAFRuGp3OR9e/6spsjBQFBOSe5w90DqLn9pjvLvlM0Hfyqp5XD3gljDY60QTkMTwyP7+4f8GDQZVsDK1MBOB7XsRFwkXo+b10FGJXZZfv3dS5eWvz0RtRmqDf/+mPm9eAfC9499DxqaSGpSIC8hhUI/HP7/14tjZZSs9G7VeL44hzEXLf93pWzOi1Tmut3Rq97jgAAgboMfTKWrazJJWRyiiT73a+EZAxViaVEcF5Hnls86oFgR9GURBxP/DLoj30/47jdnohXvmRiKSShVLS6LdffjaSjzdpIAARhqVz2qP2IQBBEkYJjxLxXNc9134E1vMlDxUPC99HAkLKtPryzo3xKmTXs6w9B18qdefpUw/3oocQWBmdEwL5nvO8zXJRGnEHMCjPEoIbl1JFAARiA04BICL77jRJDRyYLWafYCN/1DqXaZVpaYqhjzuFDO3MfjN3WKBXzkdm1Fq3s9Zuy9Fczo1DKgpyZX239F2C8OjcnKW9ECFKIhESAJClwpHd/NwXeSGllFIWRVFmNaKQl5WsUe6jzJOlWlEA8HL9ZDTC2reI0oH5w29/NzyRGIVhFPCYi5L24IgeN1dvLN+3hdt8hwSAnv8eTy7yGHzu+ge0ZfrlnVvajMmoE3iO9Z0RYsgiziPORRjsSiVkWmVGlbaVAELPj4MwDrg2eaaeN4qXYfzD5ScPl5+UYTwiJiI6v3h6FAHqKf/LH7ayrsuJ+7xMfwCAI+oakxoj810b5W8ZG8urw6OwMAh/cPRkPU7KdKIl2zD5U+OWba42iQMBcIJ539sXVSZE4jOvDJKlyrqmI40aUX4QQOdFpnWqlXUOBwE824vKz5T86s51lauSS8SYd3zuSD2qrXdbf/78g0GWCxFyZ9cAGwBFUVL3IQ5FxHm0g5hl6L4FGzO/n9+5fmZh8eS+w4nolV8IaD3rXn74MM/zt18PDWI3BhvKaSUIIArDWIhYRIgMyseR8k9c9qlRbjjnkBjzTs7OHZ6aQoa99BgS6+daRoSH7P7qSjvregzKpDBDxmDXrQwElBktc136qoSEHjOuaGWdv3zx8QsZfQLwASJwgsgHoAEb+9XX3KbAVJ6fgH526r1aXLl47PTB6X3lU+qIUtXtdJYbWSt35m2XoD7Y7//0x833SaW9F3Ec8jJU0c4Waw/yxgPt3GaTRACh71V4mAgR+H7P00XmeWwsHBdL7vDMbL2a9FQOAdEI/Ar0erRHQOvsk9bjv179rHAWXszoE9mw0g7r3QEDQBpV/tnm3NsXmDZmfkM/EEGYhLwqepoenW11Vu+s3MjzYrxKaCw7uQwFgw0e9UaIkJ8/cjwRUSkuXlEkWiZGejanoSqIIPSDOOGx4B7zylxLV5tUa6lHep4IgAd+xHkccsAew96SS02WGaX24DFQSVUBBCiKotHJDs3MTVZqL2X0Ea1JO7rdQbSAQAipkV88uPbK0HKrAtPG3AcArLQb//urv89UJ0UQYknfI+p0s5XldrvdKsbnCY2LEDEUDLYopMUhj0Ieh6Jsg2CIlBdGy8ykxRZWzPe8UzOH99WmEbHspVjrtD64vtTMump4+LYLIEBhHbmSZo+O3Gq7tfTgTm524TFIraXWmVZ9qj746NdEbX5y7r9d/MULGX0EKAAyYBn0+MpEqVZSmldmorcpMA1ch1JLdWR65cGthAvWY8pSXuDy8tqd2/eKwo5FCb3uTdDYH377u1eUQsrmHkDP4t2n3zxsPnA0PBYL/SDxwoTxgHpJXmX0etb4evmuv6dszUvn95EhstIdIee6mep0pDb5zo2kMubLe99kZXoTkYAYw2NzC8fnDlai+OVJIC9SlUiV9oWACFyp/ra73g4LTIO1/PGJc88nE9GSbcjsWbvVbrdtMZ4Wl9fajc9gaypaGXQIzoEIAYs8t8ozigo7JGsCpRULwjr5iS8YMgCwzvoIB6tTWW5GfJ4QByEjlazthIcVLngwjKi0BZTRRptBfrysa4ogTELhDyEDMRtw63N0Xpm0Zsg8YK/svd9JgalXCLr4/mxtMhHi+RkRjU/315/ef/KosEMe1D3gtW6Ctp1iiIU4v3gqCksCHiGxPHMqtVIZZ4em7ygM/BMnTk7WJ8ptGBiiLvInrdWAecOO3xX6LNteMRWnJ2pnjx4NQn/ngR4SMYfseW4ZEBjC8EYLQiiYKxgRKy+ISRRNxJOj74f0XEtVJ6aqtVjwiPMylAeGhStaZJvOFrYYPQIZIyFiKLYVIB6VvTsi5KXTYJy9fu/e08aaAxoei3EuRCREhIwBgHNOa2VyZYwedS6odGR77c2MsTiMI7G7RCIBMZRls2LvbDS8z8IWVklppLSFKSNJBEx4/M6hwyNmokv0tRQPg+DcoRP1uIK9gRAwpq3umqyrdW7tNtO2w9hqXISIodhOgBCgGiXvHTnBg7B0XU2Rr6jmame9m3Xc1jWEQScyIZFW1EzJ2T0PEQFSgAbAOqAB2NAev+sMkwPKiLmehwa+58c8inkUeP7Gk5XJ96erzx4+fECuRzsqw0wRhjzcOyf6JRCACMKpam2mNpGICHtMJwJwt5cf31t95hxtZcVea2y1c7zCt425iEIRBWGfhowW7NK9pfVOY7PhQACdm3LvKSJXup4FWeWpUbZ0RQDKi79pfVPrUhARwDlSuZZa63wXOQICZpGVlQkAsM5OT0xM1+sWXngYLLl2lj5NW890WlgLiOX4HY2Dz/HykEAE/AdHTlV4XP4LIuZFIa3KCrmVFXt7NpjeSXD0fNIQQRstncuMcUMyilgU9vqTO42s1fsNAnk+eAmNZMBQOVt58pg11wsaPJG03mlef3RrV4l/BAhy1qcjgs+8+41nt9eWtTbW2TLWSo1a6zSXntz9/N4NA+Swp1BFyCMelfXB8aJXo+UcEaHs0Gdorc5NpnK51a7cb8lOZz1W31bW1JFb77bLDhiksjeTydyup90Ha8/Yi8E5AqRKrjaaqZJEPSfJEetotdxqdPUem+cQQGpD2ZrIZW+TFwRH1FHZ4/Vn91aeVKJkh2dea7eyQiEAISJB7ixI+cW1a4HFI/vmEZGAOjq7fHdpdbXRMcoU+fPuAqDDM7Nr3aYaUg8cFavthjSyXyxBBCJnbzy8URV8fmr/5sulWs7UJu6tPLl0/EyqJbT3fukRPaTeJpuZVp/dWtosQETUkdlKe3213dK5KblBIuQJFzP1yap4njtBAG3teqf9rNXoZB1b7oLgiHvBXH1ytj5VTSp749IgYKqylXbjWWtdGtNXQMD9YLY+NVubrMXJDs9cav6VdiPVakBq536YcJGIiHkeEWW5ypSURvUUL4EIwliImdpkNYpjLl4HYzDTcqXdXGk1Mt2vPZOrx5XZ+uRsfTr0gs03OK5dMmMuLh0/M4Z9os8cPDrUFyOg5cbaR9f/0Uw7ujCIKI2WRmfGXDpxbqY+mYgoDgIESLX+WN9uykfO5owxAkJEwYIFXnvv2DtesHcOs7X281tLa+1mz5dCRCT0YKpaf3fxWBJGOxRMAlppNf5t6Yuukn05BGNNnubraYeo353ed9SxlyvyLyy+szi/4I8hGbHFwIieNtf//eoX5RIQEBB2pD51YOrI7EI1ise18eNmjGeX1m2UGBHVoorU6t+XviDqc54IAejao7uaBb+cmw89linplPOdYugsYN9rxsn65IVz5/dPzwS7JO4MgADNtHP6wOLN5YeOiJUKHgmCPKkV+yYmpitTbmfObaZVSfWH0gvC3g+DTg8i6u2CVlJYiULfr0e1A1NzR2b3+69vN0yi0A+mKvWsX6wlJMbw0erquUPHDs/u83DLSyspy9x6FEURH0OKYVd4tVZg/U5K4QepypDKnZ4oM0oWuVi++6BakXl65cEtKVVmDJBjWGboWEUkc1Mz9Vo9CMM9c0FTrVpZ+sGNf1gqNzQtebboe77DQgT+ziMjhnjzyX0cVMLK5NKLKS3q/QcB82Iu6jz46YkT+6dmXrl350hArEbxD4+dXOu0Mq2AARKa3GiXSiOdI89/vokpAuQmT2UqZZY7K7W5srTk1+q/PP/DmI+62fJu8WoBQgLHmAqF4lGuM24HTAMCco1O81//8bEjlympTI79jsQ4FImIFucWfnLqbLibZPFQfHZrSeValYRzAgBwDoSrna6fyQuCHedliOjs/iO3lx8RlCEkwnNh6nOTAYnAY1gR8dmDixePnq7GSSzE6zMiJWIuoiDkPns+DgRjjMxVqmXdqzjntMkLWzgiZ+31G9dvP75Z5NQiSguzEJA0GrA2/kzDtni1ABGQj8xOzXYXDvFuwxXPaYDkXFdl3R6DD8qSchkMR6H41dkLi3MLiYhEEI54T5eOn2llXY+xJ83VwjoEZMiMdbeW1w/OHtr5eSIuAh5G3EMG4KDfM9Cvj0DfOpNj6B2enb90/OzsxFQwjHI/diBixHnIw5BznRskAkST2w9vXK3FtTy3IgwfPXv2ZG2FhUwptdpav9NqGqcdhOB55AG8ThW5FbYUoIFDnXABjJ2NE5NUP40SbYvcOcTezhKlMwTQ70IEIIIoFDO1+sHpualqffTHNuZitjbx3y/+4pNvroRhkBeWARIQ84VX2Wn89cLZpiYzk0tlpNJlgI79XyU8ijgngtDzDk7vm0iqged/axvw1iu1c8fOPrnyBeTr5YMocwPd7r9+cfnS8VPLq2uVRCw9upVpxZini7wIfGuBCErt+EZIjMMFaOM7K6A2kXAxg/iT+UOs3fz8zvWOMUW53wBAv5mTem/SIIhCPlWp/ez0DypRPK5birlgjL3/zvlUSzvozPD8hEd+sDv7WBHxP53+ycPpZ59cX1rHdYasGsWB5zuCKOAXj5+uxgkQeJ5X4cLzvbFQcncChizmccyjJAxSYD5YAGAI2shWuvaXLz6OeJg9lIAgcwMDaib0XNI3o3+GCtDmd1aUzZTVOLl04hxD78qjux0tM6N6+z3195HnfhgLMZlUf3HmhwtTM2Os3hEAD0IehFOV2tDf7hxxGEVBFAeRh95nt5YOzuw7OX+AMY+Iym7RWLyQ6fkWV4UYQlXEE9XpQkupsrKJChFTrRBR5rJ098tEIz3334iQvamOoOEaaHOanAAC368klR+dfm9hZt9fr34u1xSVG+z0GunR8/zFuYXzi6cmkkrMo7e2RRcRojBcnNu/MDXjeV5FRKHnv5HHdyNK9stkLfrRmYUv7nSWbq95EPQrkKzPIOjlpnpbEpeB4Rsd+nANdHh2/t7Kk1+dvbAxP0QAYRDwIESExZl5BkE3zzo600WeCJ6EURTwhMeXby29/855ZfTb/LImxlgtTgYf37j0lGCIUyK+A+37leuJX1fGIA7YJuWGyhs2XO+1zg42KXkzN/GyAJUVsc9uLcVc3F9ZPnPw6KavUBgEPz797tkjqqnkh/dvK91arM0cnd0vc/1vVy4nIvoev6zpdaMgd9g7/MvgF5/wJauDwhbPU1bQf+nWywkFJNyS9fG6MUQDbV/mpfKVMyGfqtUntZ6dmDBFXgk5A/y/X39aPtZvtj783QUBhBDMsNn3psNsrviss+SAWO9XJSMLof8ZAABxUNp5U/7CEAHa4csQEaDKebWfO8+0GstbFL9zr7wcL8p4paRh+Z4PJZd8wI0hQERk6KwDQLQuDkTCOXpBzKPt2f6vCUNeebnnJRx97b/3r7zcCRBQG/PpN1c/uvH1etpyRIjUUzYEge8Fvs+D0JLzgVUye+Hc+SCKGpm6eOLEVKX6LbtCr3jt97eJt+d9omPEHh4qBMitbafdD65/9c3yg0xLEXJkLA6Ftbawxf7JmUpciTnPsvRAfaZodA8dP5ZUKggY8bHRbXeIHVEsvjWz8paw7MaFvSlUAgg8rxonPz15LgyDhEer7eaJ/YcqInKO1jsdqc2ZQ4c9jzHGrMn5gZAh8jB8I29KeLUG+tbMyvfMfo2oUBFA5cY5lxnNg5AhxlxY57TJAcD3GA/2SI8ZL3Zkwn7/pz+WP/zht797zeP5XuE/wrz9fxEnVtq4RgYkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=192x64 at 0x7F906795EE50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "do = True\n",
    "while do or decode_target(target) == decode(output_argmax[0]):\n",
    "    do = False\n",
    "    image, target, input_length, label_length = dataset[0]\n",
    "    print('true:', decode_target(target))\n",
    "\n",
    "    output = model(image.unsqueeze(0).cuda())\n",
    "    output_argmax = output.detach().permute(1, 0, 2).argmax(dim=-1)\n",
    "    print('pred:', decode(output_argmax[0]))\n",
    "to_pil_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec36de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
